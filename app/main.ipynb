{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f96c411",
   "metadata": {},
   "source": [
    "# RAG Backend API demo\n",
    "\n",
    "This notebook demonstrates the complete end-to-end flow of this mvp.\n",
    "\n",
    "## Features:\n",
    "1. Document ingestion\n",
    "2. Rag Chat\n",
    "3. Multi Turn Conversations\n",
    "4. Interview Booking\n",
    "5. Session Management\n",
    "\n",
    "**Note:** Make sure to run the backend server before executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e15eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Base URL: http://localhost:8000\n",
      " Timestamp: 2025-11-14 16:17:14\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "print(f\"API Base URL: {API_BASE_URL}\")\n",
    "print(f\" Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd921a3",
   "metadata": {},
   "source": [
    "# 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43776b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: rag-documents-cohere\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY= os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "try:\n",
    "    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "    index.delete(delete_all=True)\n",
    "    print(f\"Index: {PINECONE_INDEX_NAME}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error clearing index: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b38bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document created: sample_document.txt\n"
     ]
    }
   ],
   "source": [
    "sample_content = \"\"\"\n",
    "Product Documentation: AI-Powered Interview Scheduler\n",
    "\n",
    "Overview:\n",
    "Our AI-powered interview scheduling platform streamlines the hiring process by automating \n",
    "interview coordination, candidate communication, and schedule optimization.\n",
    "\n",
    "Key Features:\n",
    "1. Automated Scheduling: Intelligent matching of candidate and interviewer availability\n",
    "2. Multi-timezone Support: Seamlessly coordinate across different time zones\n",
    "3. Calendar Integration: Sync with Google Calendar, Outlook, and other major platforms\n",
    "4. AI-Powered Recommendations: Smart suggestions for optimal interview times\n",
    "5. Candidate Self-Service: Allow candidates to pick from available slots\n",
    "\n",
    "Technical Specifications:\n",
    "- Built with FastAPI and Python 3.11+\n",
    "- Uses PostgreSQL for data persistence\n",
    "- Redis for caching and session management\n",
    "- Pinecone for vector similarity search\n",
    "- Groq LLM for intelligent conversation\n",
    "- RESTful API architecture\n",
    "\n",
    "Interview Types Supported:\n",
    "- Phone Screening (30 minutes)\n",
    "- Technical Interview (60 minutes)\n",
    "- Behavioral Interview (45 minutes)\n",
    "- Final Round Interview (90 minutes)\n",
    "\n",
    "Contact Information:\n",
    "For support, email: support@example.com\n",
    "Website: https://interview-scheduler.example.com\n",
    "\n",
    "Current Hiring Roles for AI Engineer Position:\n",
    "\n",
    "1) Senior AI Engineer - Full-time\n",
    "    - Seniority: Senior (5+ years)\n",
    "    - Location: Remote or Hybrid\n",
    "    - Responsibilities:\n",
    "      * Design and implement machine learning models for interview matching algorithms\n",
    "      * Develop NLP pipelines for resume parsing and candidate-job matching\n",
    "      * Build recommendation systems for optimal interview scheduling\n",
    "      * Work with LLMs for conversational AI and candidate screening\n",
    "      * Optimize embedding models and vector search for semantic matching\n",
    "    - Tech stack: Python, PyTorch/TensorFlow, Transformers, LangChain, Cohere, OpenAI API\n",
    "    - Requirements: PhD or Masters in CS/AI, strong publication record, experience with production ML systems\n",
    "\n",
    "2) ML Engineer (Embeddings & RAG) - Full-time\n",
    "    - Seniority: Mid to Senior (3+ years)\n",
    "    - Location: Remote\n",
    "    - Responsibilities:\n",
    "      * Design and optimize RAG (Retrieval-Augmented Generation) pipelines\n",
    "      * Fine-tune embedding models for domain-specific search\n",
    "      * Implement vector databases and similarity search algorithms\n",
    "      * Evaluate and improve context retrieval quality\n",
    "      * A/B test different embedding strategies and chunking methods\n",
    "    - Tech stack: Python, Cohere, Pinecone, Qdrant, sentence-transformers, NumPy\n",
    "    - Requirements: Strong understanding of embeddings, vector databases, and information retrieval\n",
    "\n",
    "3) AI Research Engineer - Contract\n",
    "    - Seniority: Senior (4+ years)\n",
    "    - Location: Remote\n",
    "    - Responsibilities:\n",
    "      * Research state-of-the-art LLM techniques for interview automation\n",
    "      * Experiment with prompt engineering and chain-of-thought reasoning\n",
    "      * Develop evaluation metrics for AI-generated responses\n",
    "      * Prototype new AI features for candidate assessment\n",
    "    - Tech stack: Python, GPT-4, Claude, Llama, prompt engineering frameworks\n",
    "    - Requirements: Strong research background, experience with LLM APIs, ability to publish findings\n",
    "\n",
    "4) MLOps Engineer - Full-time\n",
    "    - Seniority: Mid to Senior (3+ years)\n",
    "    - Location: Remote or Hybrid\n",
    "    - Responsibilities:\n",
    "      * Build CI/CD pipelines for ML model deployment\n",
    "      * Monitor model performance and data drift\n",
    "      * Implement A/B testing infrastructure for ML experiments\n",
    "      * Optimize inference latency and cost\n",
    "      * Manage model versioning and experiment tracking\n",
    "    - Tech stack: Docker, Kubernetes, MLflow, W&B, Prometheus, FastAPI\n",
    "    - Requirements: Experience deploying ML models to production, strong DevOps skills\n",
    "\n",
    "5) Data Scientist (AI/ML) - Full-time\n",
    "    - Seniority: Mid (2+ years)\n",
    "    - Location: Remote\n",
    "    - Responsibilities:\n",
    "      * Analyze user behavior and interview success metrics\n",
    "      * Build predictive models for interview outcomes\n",
    "      * Create dashboards and reports on AI system performance\n",
    "      * Conduct statistical analysis of matching algorithms\n",
    "    - Tech stack: Python, pandas, scikit-learn, SQL, Jupyter, Tableau\n",
    "    - Requirements: Strong statistics background, experience with A/B testing, data visualization\n",
    "\n",
    "How to Apply:\n",
    "- Send your resume to careers@example.com with \"AI Engineer - [Role Name]\" in subject\n",
    "- Include a cover letter explaining your AI/ML experience\n",
    "- Portfolio or GitHub links showcasing ML projects strongly preferred\n",
    "- Research papers or technical blog posts are a plus\n",
    "\n",
    "Interview Process:\n",
    "1. Initial screening call (30 min)\n",
    "2. Technical assessment - ML coding challenge\n",
    "3. System design interview - AI architecture\n",
    "4. Team interview - cultural fit and collaboration\n",
    "5. Final round with leadership\n",
    "\n",
    "Benefits:\n",
    "- Competitive salary with equity\n",
    "- Remote-first culture\n",
    "- Professional development budget\n",
    "- Conference attendance support\n",
    "- Health insurance and 401k\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_document.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_content)\n",
    "\n",
    "print(\"Sample document created: sample_document.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687d18f",
   "metadata": {},
   "source": [
    "# 2. Document Ingestion\n",
    "Upload text or pdf to the system for processing.\n",
    "\n",
    "- Extract text from the document\n",
    "- Chunk the text\n",
    "- Generate embeddings\n",
    "- Store in vector database\n",
    "- Save metadata in the database (postgresql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0409108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting document ingestion...\n",
      " Document ingested successfully!\n",
      " Document ID: e315ffde-045b-45e8-be7b-092edf5f0933\n",
      " Filename: sample_document.txt\n",
      " Total Chunks: 3\n",
      " Chunking Strategy: semantic\n",
      " Vector Store: pinecone\n",
      "Created At: 2025-11-14T10:52:06.087060\n",
      " Message: Document ingested successfully\n",
      "\n",
      " Document is now ready for RAG queries!\n"
     ]
    }
   ],
   "source": [
    "url = f\"{API_BASE_URL}/api/ingest\"\n",
    "print(\" Starting document ingestion...\")\n",
    "\n",
    "with open(\"sample_document.txt\", \"rb\") as f:\n",
    "    files = {\"file\": (\"sample_document.txt\", f, \"text/plain\")}\n",
    "    \n",
    "    data = {\n",
    "        \"chunking_type\": \"semantic\", \n",
    "        \"chunk_size\": 500,\n",
    "        \"chunk_overlap\": 50\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, files=files, data=data, timeout=30)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\" Request timed out after 30 seconds\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\" Could not connect to API at http://localhost:8000\")\n",
    "    else:\n",
    "        if response.status_code == 200:\n",
    "            print(\" Document ingested successfully!\")\n",
    "            result = response.json()\n",
    "            print(f\" Document ID: {result.get('document_id', 'N/A')}\")\n",
    "            print(f\" Filename: {result.get('filename', 'N/A')}\")\n",
    "            print(f\" Total Chunks: {result.get('total_chunks', 0)}\")\n",
    "            print(f\" Chunking Strategy: {result.get('chunking_strategy', 'N/A')}\")\n",
    "            print(f\" Vector Store: {result.get('vector_store', 'N/A')}\")\n",
    "            print(f\"Created At: {result.get('created_at', 'N/A')}\")\n",
    "            print(f\" Message: {result.get('message', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\n Document is now ready for RAG queries!\")\n",
    "        else:\n",
    "            print(f\" Document ingestion failed with status: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b36e27",
   "metadata": {},
   "source": [
    "# 3. Rag Chat\n",
    "Now that we have documents ingested, let's ask questions using RAG (Retrieval-Augmented Generation).\n",
    "\n",
    "The system will:\n",
    "1. Embed your query\n",
    "2. Search Pinecone for similar document chunks\n",
    "3. Send context + query to LLM (Groq)\n",
    "4. Return an informed answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Chat Session ID: 5ee00b12-823f-4b29-a6c9-7c5a649dead8\n",
      "\n",
      "Chat response received!\n",
      "\n",
      "Answer:\n",
      "We are currently hiring for the following AI Engineer positions:\n",
      "\n",
      "1. **Senior AI Engineer** - Full-time: Design and implement machine learning models for interview matching algorithms, develop NLP pipelines, and build recommendation systems.\n",
      "2. **ML Engineer (Embeddings & RAG)** - Full-time: Design and optimize RAG pipelines, fine-tune embedding models, and implement vector databases and similarity search algorithms.\n",
      "3. **AI Research Engineer** - Contract: Research state-of-the-art LLM techniques for interview automation, experiment with prompt engineering, and develop evaluation metrics for AI-generated responses.\n",
      "4. **MLOps Engineer** - Full-time: Build CI/CD pipelines for ML model deployment, monitor model performance, and implement A/B testing infrastructure.\n",
      "5. **Data Scientist (AI/ML)** - Full-time: Analyze user behavior, build predictive models, create dashboards, and conduct statistical analysis of matching algorithms.\n",
      "\n",
      "If you're interested in any of these roles, please send your resume to careers@example.com with the role name in the subject line, along with a cover letter and any relevant portfolio or GitHub links.\n",
      "\n",
      "Number of sources used: 2\n",
      "\n",
      "Source chunks:\n",
      "\n",
      "  Source 1:\n",
      "    File: sample_document.txt\n",
      "    Similarity Score: 0.3969\n",
      "    Text Preview: Product Documentation: AI-Powered Interview Scheduler\n",
      "\n",
      "Overview:\n",
      "Our AI-powered interview scheduling platform streamlines the hiring process by aut...\n",
      "\n",
      "  Source 2:\n",
      "    File: sample_document.txt\n",
      "    Similarity Score: 0.4692\n",
      "    Text Preview: Candidate Self-Service: Allow candidates to pick from available slots\n",
      "\n",
      "Technical Specifications:\n",
      "- Built with FastAPI and Python 3.11+\n",
      "- Uses Post...\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "print(f\"New Chat Session ID: {session_id}\\n\")\n",
    "\n",
    "url = f\"{API_BASE_URL}/api/chat\"\n",
    "payload = {\n",
    "    \"query\": \"Which roles are u hiring?\",\n",
    "    \"session_id\": session_id,\n",
    "    \"top_k\": 5\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Chat response received!\\n\")\n",
    "    print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "    \n",
    "    contexts = result.get('retrieved_contexts', [])\n",
    "    print(f\"Number of sources used: {len(contexts)}\")\n",
    "    print(f\"\\nSource chunks:\")\n",
    "    for i, ctx in enumerate(contexts, 1):\n",
    "        print(f\"\\n  Source {i}:\")\n",
    "        print(f\"    File: {ctx.get('filename', 'N/A')}\")\n",
    "        print(f\"    Similarity Score: {ctx.get('similarity_score', 0):.4f}\")\n",
    "        print(f\"    Text Preview: {ctx.get('chunk_text', '')[:150]}...\")\n",
    "    \n",
    "    if result.get('booking_detected'):\n",
    "        print(f\"\\nBooking detected! ID: {result.get('booking_id', 'N/A')}\")\n",
    "\n",
    "else:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498aed2",
   "metadata": {},
   "source": [
    "## 4. Multi-turn Conversation\n",
    "\n",
    "Continue the conversation with follow-up questions. The system maintains chat history in Redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198032cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer:\n",
      "Our AI-powered interview scheduling platform supports the following types of interviews, along with their respective durations:\n",
      "\n",
      "1. **Phone Screening**: 30 minutes\n",
      "2. **Technical Interview**: 60 minutes\n",
      "3. **Behavioral Interview**: 45 minutes\n",
      "4. **Final Round Interview**: 90 minutes\n",
      "\n",
      "These interview types and durations can be easily scheduled and managed through our platform, which streamlines the hiring process and optimizes interview coordination.\n",
      "\n",
      " This conversation has context from previous messages\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"query\": \"What interview types are supported and how long is each?\",\n",
    "    \"session_id\": session_id,\n",
    "    \"top_k\": 5\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_BASE_URL}/api/chat\", json=payload, headers=HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\" Answer:\\n{result['answer']}\\n\")\n",
    "    print(f\" This conversation has context from previous messages\")\n",
    "else:\n",
    "    print(f\"Request failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b42c18",
   "metadata": {},
   "source": [
    "## 5. Interview Booking Extraction\n",
    "\n",
    "The system can automatically detect and extract interview booking information from conversations.\n",
    "\n",
    "Try asking to schedule an interview with specific details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e75801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking request processed!\n",
      "\n",
      "Answer:\n",
      "I'd be happy to help you schedule a technical interview for Anuj Bhandari.\n",
      "\n",
      "Here are the details:\n",
      "\n",
      "* Candidate Name: Anuj Bhandari\n",
      "* Email: anuzb50@gmail.com\n",
      "* Interview Type: Technical Interview (60 minutes)\n",
      "* Preferred Date and Time: November 12, 2025, at 2:00 PM\n",
      "* Relevant Experience: 5 years of Python experience\n",
      "\n",
      "I've checked our availability, and we have a slot open on November 12, 2025, at 2:00 PM. I'm going to go ahead and book the technical interview for Anuj.\n",
      "\n",
      "You will receive a confirmation email with the interview details, and Anuj will receive a separate email with instructions on how to join the interview.\n",
      "\n",
      "Please note that our technical interview will assess Anuj's problem-solving skills, coding abilities, and experience with Python. If you have any specific requirements or questions you'd like us to cover during the interview, please let me know.\n",
      "\n",
      "Is there anything else I can assist you with?\n",
      "\n",
      "✅ Interview booking created successfully!\n",
      "- Name: Anuj Bhandari\n",
      "- Email: anuzb50@gmail.com\n",
      "- Date: 2025-11-12\n",
      "- Time: 14:00\n",
      "- Booking ID: d9c91267-6f75-4efb-9a12-d344e5d88dc4\n",
      "\n",
      "Booking information successfully extracted and saved!\n",
      "Booking ID: d9c91267-6f75-4efb-9a12-d344e5d88dc4\n",
      "\n",
      "Run the next cell to see all bookings!\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"query\": \"I'd like to book a technical interview for Anuj Bhandari. His email is anuzb50@gmail.com. He prefers November 12, 2025 at 2:00 PM. He has 5 years of Python experience.\",\n",
    "    \"session_id\": session_id,\n",
    "    \"top_k\": 3\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_BASE_URL}/api/chat\", json=payload, headers=HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"Booking request processed!\\n\")\n",
    "    print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "    \n",
    "    if result.get('booking_detected'):\n",
    "        print(\"Booking information successfully extracted and saved!\")\n",
    "        print(f\"Booking ID: {result.get('booking_id', 'N/A')}\")\n",
    "        print(\"\\nRun the next cell to see all bookings!\")\n",
    "    else:\n",
    "        print(\"No booking information detected in this message\")\n",
    "        print(\"\\nDebug info:\")\n",
    "        print(f\"   Response keys: {list(result.keys())}\")\n",
    "        print(f\"   Booking detected: {result.get('booking_detected', False)}\")\n",
    "else:\n",
    "    print(f\"Request failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27006373",
   "metadata": {},
   "source": [
    "## 6. Retrieve All Bookings\n",
    "\n",
    "Get all interview bookings stored in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43a0dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 booking(s)\n",
      "\n",
      "============================================================\n",
      "Booking #1\n",
      "============================================================\n",
      "ID: d9c91267-6f75-4efb-9a12-d344e5d88dc4\n",
      "Name: Anuj Bhandari\n",
      "Email: anuzb50@gmail.com\n",
      "Date: 2025-11-12\n",
      "Time: 14:00\n",
      "Additional Notes: He has 5 years of Python experience.\n",
      "Status: pending\n",
      "Created At: 2025-11-14T10:52:20.846883\n",
      "\n",
      "============================================================\n",
      "Booking #2\n",
      "============================================================\n",
      "ID: 1523ea44-5332-4d98-b980-bb32636902fe\n",
      "Name: Anuj Bhandari\n",
      "Email: anuzb50@gmail.com\n",
      "Date: 2025-11-12\n",
      "Time: 14:00\n",
      "Additional Notes: He has 5 years of Python experience.\n",
      "Status: pending\n",
      "Created At: 2025-11-14T10:43:12.979284\n",
      "\n",
      "============================================================\n",
      "Booking #3\n",
      "============================================================\n",
      "ID: b3c696d4-90b1-4298-9ee2-7f28c025ea3e\n",
      "Name: Anuj Bhandari\n",
      "Email: anuzb50@gmail.com\n",
      "Date: 2025-12-15\n",
      "Time: 14:00\n",
      "Additional Notes: He has 5 years of Python experience.\n",
      "Status: pending\n",
      "Created At: 2025-11-14T10:42:44.722871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(f\"{API_BASE_URL}/api/bookings\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    bookings = data.get('bookings', [])\n",
    "    total = data.get('total', 0)\n",
    "    \n",
    "    print(f\"Retrieved {total} booking(s)\\n\")\n",
    "    \n",
    "    if bookings:\n",
    "        for i, booking in enumerate(bookings, 1):\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Booking #{i}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"ID: {booking.get('booking_id', 'N/A')}\")\n",
    "            print(f\"Name: {booking.get('name', 'N/A')}\")\n",
    "            print(f\"Email: {booking.get('email', 'N/A')}\")\n",
    "            print(f\"Date: {booking.get('date', 'N/A')}\")\n",
    "            print(f\"Time: {booking.get('time', 'N/A')}\")\n",
    "            print(f\"Additional Notes: {booking.get('additional_notes', 'N/A')}\")\n",
    "            print(f\"Status: {booking.get('status', 'N/A')}\")\n",
    "            print(f\"Created At: {booking.get('created_at', 'N/A')}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No bookings found in the system\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve bookings: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3b302",
   "metadata": {},
   "source": [
    "## 7. Advanced Examples\n",
    "\n",
    "Let's try some more complex queries to demonstrate the RAG capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "729ebd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Session: c566f346-5f09-4171-bcfb-7fb30917207a\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Query 1: What technologies are used to build the platform?\n",
      "----------------------------------------------------------------------\n",
      "Answer: The AI-Powered Interview Scheduler platform is built using the following technologies:\n",
      "\n",
      "1. **FastAPI**: A modern, fast (high-performance), web framework for building APIs.\n",
      "2. **Python 3.11+**: The programming language used for development.\n",
      "3. **PostgreSQL**: A powerful, open-source relational database management system used for data persistence.\n",
      "4. **Redis**: An in-memory data store used for caching and session management.\n",
      "5. **Pinecone**: A vector database used for vector similarity search.\n",
      "6. **Groq LLM**: A large language model used for intelligent conversation.\n",
      "\n",
      "Additionally, the platform also integrates with popular calendar platforms, including:\n",
      "\n",
      "1. **Google Calendar**\n",
      "2. **Outlook**\n",
      "\n",
      "The platform follows a **RESTful API architecture**, ensuring a scalable and maintainable design.\n",
      "\n",
      "Sources: 2 chunks used\n",
      "Top similarity score: 0.3885\n",
      "======================================================================\n",
      "\n",
      "Query 2: How can I integrate the system with my calendar?\n",
      "----------------------------------------------------------------------\n",
      "Answer: Integrating the AI-Powered Interview Scheduler with your calendar is a straightforward process. According to the product documentation, the platform supports integration with major calendar platforms, including:\n",
      "\n",
      "1. **Google Calendar**\n",
      "2. **Outlook**\n",
      "\n",
      "To integrate the system with your calendar, you can follow these general steps:\n",
      "\n",
      "1. **Authorize access**: Grant the AI-Powered Interview Scheduler permission to access your calendar by authenticating through the respective calendar platform's API.\n",
      "2. **Configure calendar settings**: Specify the calendar account you want to integrate with the platform, and set up any additional preferences, such as scheduling rules or notifications.\n",
      "3. **Sync calendars**: The platform will sync with your calendar to retrieve availability and schedule interviews.\n",
      "\n",
      "The platform's **Calendar Integration** feature (as mentioned in the key features) enables seamless coordination across different calendars, ensuring that interviews are scheduled efficiently and effectively.\n",
      "\n",
      "If you need more detailed instructions or have specific questions about integrating with your calendar, I'd be happy to help. Additionally, I can assist with scheduling a demo or support session to walk you through the integration process. Would you like me to schedule a demo for you?\n",
      "\n",
      "Sources: 1 chunks used\n",
      "Top similarity score: 0.3542\n",
      "======================================================================\n",
      "\n",
      "Query 3: What's the contact email for support?\n",
      "----------------------------------------------------------------------\n",
      "Answer: Unfortunately, I don't have any specific contact information, including a support email, as the context doesn't provide any relevant details. However, I can offer some general assistance.\n",
      "\n",
      "If you're looking for support, I can suggest some alternatives:\n",
      "\n",
      "1. **Check the official website**: You can try visiting the official website of the AI-Powered Interview Scheduler to see if they have a contact page or a support email listed.\n",
      "2. **Look for a help center**: Many platforms have a help center or a knowledge base that provides answers to frequently asked questions and troubleshooting guides.\n",
      "3. **Reach out to me**: I can try to assist you with any questions or concerns you may have, and I can also help facilitate a support request if needed.\n",
      "\n",
      "Please let me know how I can further assist you, and I'll do my best to provide a helpful response. If you'd like, I can also help with scheduling a support session or a demo. Just let me know!\n",
      "\n",
      "Sources: 0 chunks used\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "new_session_id = str(uuid.uuid4())\n",
    "\n",
    "queries = [\n",
    "    \"What technologies are used to build the platform?\",\n",
    "    \"How can I integrate the system with my calendar?\",\n",
    "    \"What's the contact email for support?\",\n",
    "]\n",
    "\n",
    "print(f\"New Session: {new_session_id}\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"session_id\": new_session_id,\n",
    "        \"top_k\": 3\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{API_BASE_URL}/api/chat\", json=payload, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"Answer: {result['answer']}\\n\")\n",
    "        contexts = result.get('retrieved_contexts', [])\n",
    "        print(f\"Sources: {len(contexts)} chunks used\")\n",
    "        if contexts:\n",
    "            print(f\"Top similarity score: {contexts[0].get('similarity_score', 0):.4f}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    \n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
